#!/usr/bin/env python
# -*- coding: UTF-8 -*-
'''=================================================
@Project -> File   ：qiyangPythonCrawler -> fromData
@IDE    ：PyCharm
@Author ：Mr. cyh
@Date   ：2021/4/25 14:04
@Desc   ：用于给中国供应商发送搜索关键词的的方法 获取关键词的拼接目录  关键词一定要多  这个网站非常的大  一定要够多
        最后把这个关键词在该网站中的搜索字段全部保存起来
        每一个最多有三十页  一页最多有40个

        思路:::::  这个网站有点大   思路必须搞清楚

        获取列表页的数据时候 如果返回的状态码是 404 则说明本关键词 在本网站中没有相关搜索

        RE : search/[^\s]*.shtml 获取一个页面中所有的列表页面的链接关键词

        获取其他列表页从 "您可以找"  中 有很多列表页的链接  这个不要进入 先抓取存起来  还需要进行判断

        如果列表页中 包含分类的 例如 省份 适用范围 种类等等  则需要调用对应的方法 先判断一共有多少条  条数越多  没进入下一级细分 则判断一次  如果大于1200 则在向下一级细分 (例子1)反之开始采集信息  则将分类的更加精细

        例子1
        省份有三个       共有3600条
        进入其中一个省份   判断有多少条  大于1200 则开始下线以及细分
        进入适用范围   判断有多少条  小于1200  则不进入下一层细分领域  直接开始采集
        有点像是递归


不需要再去找请求  关键词了
下面的  relatedwords 里面 全都有

https://www.china.cn/relatedwords/  里面有一个 食品相关的目录 还有一个机械食品 相关


https://www.china.cn/relatedwords/niuroulei.html     ---- 牛肉类
https://www.china.cn/relatedwords/yangroulei.html    ---- 羊肉类


从列表页进入详情页时  应该从每个表单的的标题进入 而不是公司名字进入  从公司名字处的URL 可能是自己的页面 而从标题中进入的情况下 初步预计都有 中国供应商  的头部和尾部文件  尾部文件中有电话号和地址等信息  可以减少爬虫无效操作 提高效率


准备:::
1 先把 relatedwords 相关搜索的关键词 全部拿到   再用自己准备的一些关键词去请求 获取关键词的   然后看看是不是全部都有
2 进入列表页  主营产品在列表页
列表页有两种
        一中是包含细分 的各种属性的    根据例子1 处理
        一中是不包含的  根据本列表页一共出现的相关数据 来判断要不要进入其他的相关列表页



=================================================='''
from urllib.parse import quote, unquote

gjc = [
    # 肉类 后缀是肉
    "牛肉", "羊肉", "兔肉", "猪肉", "鸡肉", "鸭肉", "驴肉", "鹅肉", "虾肉", "鱼肉", "羊肉", "羊肉", "羊肉","腊肉",

    "海产", "水产", "海鲜", "农产", "海产", "海产", "海产",
    # 蛋类
    "鸡蛋", "鸭蛋", "鸵鸟蛋", "鹌鹑蛋",
    # 米面类
    "鸡蛋", "鸭蛋", "鸵鸟蛋", "鹌鹑蛋",
    "羊肉",
    # 各种调味品相关的
    "调味", "香料",

    "食品添加剂"
    ,"腌菜","酱菜","蔬菜","腌菜","腌菜"

    # 饮品
    ,"饮料","酱菜","腌菜","腌菜","腌菜"
    # 食品机械
    ,"饮料","酱菜","腌菜","腌菜","腌菜"
]
if __name__ == '__main__':
    for g in gjc:
        gquote = quote(g)
        print(gquote)
        print(unquote(gquote))
